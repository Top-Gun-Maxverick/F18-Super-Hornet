{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "6AhT_4VcswXo"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Install and Import"
      ],
      "metadata": {
        "id": "IwiXUW2Tp3jY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ijUUME_pvH9",
        "outputId": "83826062-5688-4fde-e62f-9fe33c4a80ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m29.7/29.7 MB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pypi (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "%pip install -q rdkit pypi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from rdkit import Chem, RDLogger\n",
        "from rdkit.Chem.Draw import IPythonConsole, MolsToGridImage\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "RDLogger.DisableLog(\"rdApp.*\")"
      ],
      "metadata": {
        "id": "heOJRdA2p23S"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset"
      ],
      "metadata": {
        "id": "KdTbl79Sp-Wv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DataHelper():\n",
        "    def __init__(self):\n",
        "        csv_path = tf.keras.utils.get_file(\"qm9.csv\", \"https://deepchemdata.s3-us-west-1.amazonaws.com/datasets/qm9.csv\")\n",
        "        self.data = list()\n",
        "        with open(csv_path, \"r\")  as fin:\n",
        "            for line in fin.readlines()[1:]:\n",
        "                self.data.append(line.split(\",\")[1])\n",
        "\n",
        "    def __getitem__(self, idx: int):\n",
        "        smiles = self.data[idx]\n",
        "        print(f\"SMILES: {smiles}\")\n",
        "        mol = Chem.MolFromSmiles(smiles)\n",
        "        print(f\"Number of Heavy Atoms: {mol.GetNumHeavyAtoms()}\")\n",
        "        return mol"
      ],
      "metadata": {
        "id": "7ipVEFo-p_jO"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DH = DataHelper()"
      ],
      "metadata": {
        "id": "e8K3CcLCrTnz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89a3d688-a276-4e04-bb0c-68fa27264881"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://deepchemdata.s3-us-west-1.amazonaws.com/datasets/qm9.csv\n",
            "29856825/29856825 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Utilities"
      ],
      "metadata": {
        "id": "6N4SnjGJruEe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "atom_mapping = {\n",
        "    \"C\": 0,\n",
        "    0: \"C\",\n",
        "    \"N\": 1,\n",
        "    1: \"N\",\n",
        "    \"O\": 2,\n",
        "    2: \"O\",\n",
        "    \"F\": 3,\n",
        "    3: \"F\",\n",
        "}\n",
        "\n",
        "bond_mapping = {\n",
        "    \"SINGLE\": 0,\n",
        "    0: Chem.BondType.SINGLE,\n",
        "    \"DOUBLE\": 1,\n",
        "    1: Chem.BondType.DOUBLE,\n",
        "    \"TRIPLE\": 2,\n",
        "    2: Chem.BondType.TRIPLE,\n",
        "    \"AROMATIC\": 3,\n",
        "    3: Chem.BondType.AROMATIC,\n",
        "}\n",
        "\n",
        "NUM_ATOMS = 9  # Maximum number of atoms\n",
        "ATOM_DIM = 4 + 1  # Number of atom types\n",
        "BOND_DIM = 4 + 1  # Number of bond types\n",
        "LATENT_DIM = 64  # Size of the latent space\n",
        "\n",
        "\n",
        "def smiles_to_graph(smiles):\n",
        "    # Converts SMILES to molecule object\n",
        "    molecule = Chem.MolFromSmiles(smiles)\n",
        "\n",
        "    # Initialize adjacency and feature tensor\n",
        "    adjacency = np.zeros((BOND_DIM, NUM_ATOMS, NUM_ATOMS), \"float32\")\n",
        "    features = np.zeros((NUM_ATOMS, ATOM_DIM), \"float32\")\n",
        "\n",
        "    # loop over each atom in molecule\n",
        "    for atom in molecule.GetAtoms():\n",
        "        i = atom.GetIdx()\n",
        "        atom_type = atom_mapping[atom.GetSymbol()]\n",
        "        features[i] = np.eye(ATOM_DIM)[atom_type]\n",
        "        # loop over one-hop neighbors\n",
        "        for neighbor in atom.GetNeighbors():\n",
        "            j = neighbor.GetIdx()\n",
        "            bond = molecule.GetBondBetweenAtoms(i, j)\n",
        "            bond_type_idx = bond_mapping[bond.GetBondType().name]\n",
        "            adjacency[bond_type_idx, [i, j], [j, i]] = 1\n",
        "\n",
        "    # Where no bond, add 1 to last channel (indicating \"non-bond\")\n",
        "    # Notice: channels-first\n",
        "    adjacency[-1, np.sum(adjacency, axis=0) == 0] = 1\n",
        "\n",
        "    # Where no atom, add 1 to last column (indicating \"non-atom\")\n",
        "    features[np.where(np.sum(features, axis=1) == 0)[0], -1] = 1\n",
        "\n",
        "    return adjacency, features\n",
        "\n",
        "\n",
        "def graph_to_molecule(graph):\n",
        "    # Unpack graph\n",
        "    adjacency, features = graph\n",
        "\n",
        "    # RWMol is a molecule object intended to be edited\n",
        "    molecule = Chem.RWMol()\n",
        "\n",
        "    # Remove \"no atoms\" & atoms with no bonds\n",
        "    keep_idx = np.where(\n",
        "        (np.argmax(features, axis=1) != ATOM_DIM - 1)\n",
        "        & (np.sum(adjacency[:-1], axis=(0, 1)) != 0)\n",
        "    )[0]\n",
        "    features = features[keep_idx]\n",
        "    adjacency = adjacency[:, keep_idx, :][:, :, keep_idx]\n",
        "\n",
        "    # Add atoms to molecule\n",
        "    for atom_type_idx in np.argmax(features, axis=1):\n",
        "        atom = Chem.Atom(atom_mapping[atom_type_idx])\n",
        "        _ = molecule.AddAtom(atom)\n",
        "\n",
        "    # Add bonds between atoms in molecule; based on the upper triangles\n",
        "    # of the [symmetric] adjacency tensor\n",
        "    (bonds_ij, atoms_i, atoms_j) = np.where(np.triu(adjacency) == 1)\n",
        "    for (bond_ij, atom_i, atom_j) in zip(bonds_ij, atoms_i, atoms_j):\n",
        "        if atom_i == atom_j or bond_ij == BOND_DIM - 1:\n",
        "            continue\n",
        "        bond_type = bond_mapping[bond_ij]\n",
        "        molecule.AddBond(int(atom_i), int(atom_j), bond_type)\n",
        "\n",
        "    # Sanitize the molecule; for more information on sanitization, see\n",
        "    # https://www.rdkit.org/docs/RDKit_Book.html#molecular-sanitization\n",
        "    flag = Chem.SanitizeMol(molecule, catchErrors=True)\n",
        "    # Let's be strict. If sanitization fails, return None\n",
        "    if flag != Chem.SanitizeFlags.SANITIZE_NONE:\n",
        "        return None\n",
        "\n",
        "    return molecule"
      ],
      "metadata": {
        "id": "y0RD5YzArqgH"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generate Training Set"
      ],
      "metadata": {
        "id": "8fn0WHxksANf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "adjacency_tensor, feature_tensor = [], []\n",
        "for smiles in DH.data[::10]:\n",
        "    adjacency, features = smiles_to_graph(smiles)\n",
        "    adjacency_tensor.append(adjacency)\n",
        "    feature_tensor.append(features)\n",
        "\n",
        "adjacency_tensor = np.array(adjacency_tensor)\n",
        "feature_tensor = np.array(feature_tensor)\n",
        "\n",
        "print(\"adjacency_tensor.shape =\", adjacency_tensor.shape)\n",
        "print(\"feature_tensor.shape =\", feature_tensor.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QJxvQoAwr_Mm",
        "outputId": "cbc1018e-4118-4148-c04f-a5eb333fc4bc"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "adjacency_tensor.shape = (13389, 5, 9, 9)\n",
            "feature_tensor.shape = (13389, 9, 5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Quantum Graph Generator - TODO"
      ],
      "metadata": {
        "id": "vDeSpCJ5sVHg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Quantum LSTM Cell"
      ],
      "metadata": {
        "id": "j6AQnXNbcngm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install pennylane"
      ],
      "metadata": {
        "id": "Ld_MIVqlTK25"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pennylane as qml"
      ],
      "metadata": {
        "id": "w_ehYpzksX5d"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class QLSTMCell(keras.Model):\n",
        "    def __init__(self, input_size, hidden_size, n_qubits, n_layers=1, backend=\"default.qubit\"):\n",
        "        super(QLSTMCell, self).__init__()\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.n_qubits = n_qubits\n",
        "        self.n_layers = n_layers\n",
        "        self.backend = backend\n",
        "\n",
        "        self.wires_forget = [f\"wire_forget_{i}\" for i in range(self.n_qubits)]\n",
        "        self.wires_inputs = [f\"wire_inputs_{i}\" for i in range(self.n_qubits)]\n",
        "        self.wires_update = [f\"wire_update_{i}\" for i in range(self.n_qubits)]\n",
        "        self.wires_output = [f\"wire_output_{i}\" for i in range(self.n_qubits)]\n",
        "\n",
        "        self.dev_forget = qml.device(self.backend, wires=self.wires_forget)\n",
        "        self.dev_inputs = qml.device(self.backend, wires=self.wires_inputs)\n",
        "        self.dev_update = qml.device(self.backend, wires=self.wires_update)\n",
        "        self.dev_output = qml.device(self.backend, wires=self.wires_output)\n",
        "\n",
        "        def _circuit_forget(inputs, weights):\n",
        "            qml.templates.AngleEmbedding(inputs, wires=self.wires_forget)\n",
        "            qml.templates.BasicEntanglerLayers(weights, wires=self.wires_forget)\n",
        "            return [qml.expval(qml.PauliZ(wires=w)) for w in self.wires_forget]\n",
        "        self.qlayer_forget = qml.QNode(_circuit_forget, self.dev_forget, interface=\"tf\")\n",
        "\n",
        "        def _circuit_input(inputs, weights):\n",
        "            qml.templates.AngleEmbedding(inputs, wires=self.wires_inputs)\n",
        "            qml.templates.BasicEntanglerLayers(weights, wires=self.wires_inputs, rotation=qml.RY)\n",
        "            return [qml.expval(qml.PauliZ(wires=w)) for w in self.wires_inputs]\n",
        "        self.qlayer_inputs = qml.QNode(_circuit_input, self.dev_inputs, interface=\"tf\")\n",
        "\n",
        "        def _circuit_update(inputs, weights):\n",
        "            qml.templates.AngleEmbedding(inputs, wires=self.wires_update)\n",
        "            qml.templates.BasicEntanglerLayers(weights, wires=self.wires_update)\n",
        "            return [qml.expval(qml.PauliZ(wires=w)) for w in self.wires_update]\n",
        "        self.qlayer_update = qml.QNode(_circuit_update, self.dev_update, interface=\"tf\")\n",
        "\n",
        "        def _circuit_output(inputs, weights):\n",
        "            qml.templates.AngleEmbedding(inputs, wires=self.wires_output)\n",
        "            qml.templates.BasicEntanglerLayers(weights, wires=self.wires_output)\n",
        "            return [qml.expval(qml.PauliZ(wires=w)) for w in self.wires_output]\n",
        "        self.qlayer_output = qml.QNode(_circuit_output, self.dev_output, interface=\"tf\")\n",
        "\n",
        "        weight_shapes = {\"weights\": (n_layers, n_qubits)}\n",
        "\n",
        "        self.cell = keras.layers.Dense(input_size + hidden_size, use_bias=True)\n",
        "        # default args = xavier_uniform for weight and zeros for bias\n",
        "\n",
        "        self.VQC = {\n",
        "            'forget': qml.qnn.KerasLayer(self.qlayer_forget, weight_shapes, n_qubits),\n",
        "            'inputs': qml.qnn.KerasLayer(self.qlayer_inputs, weight_shapes, n_qubits),\n",
        "            'update': qml.qnn.KerasLayer(self.qlayer_update, weight_shapes, n_qubits),\n",
        "            'output': qml.qnn.KerasLayer(self.qlayer_output, weight_shapes, n_qubits)\n",
        "        }\n",
        "\n",
        "        self.clayer_out = keras.layers.Dense(n_qubits, use_bias=False)\n",
        "\n",
        "    def call(self, x, hidden):\n",
        "        hx, cx = hidden\n",
        "        gates = tf.concat([x, hx], axis=1)\n",
        "        gates = self.cell(gates)\n",
        "\n",
        "        for layer in range(self.n_layers):\n",
        "            ingate = keras.activations.sigmoid(self.clayer_out(self.VQC['forget'](gates)))\n",
        "            forgetgate = keras.activations.sigmoid(self.clayer_out(self.VQC['inputs'](gates)))\n",
        "            cellgate = keras.activations.tanh(self.clayer_out(self.VQC['update'](gates)))\n",
        "            outgate = keras.activations.sigmoid(self.clayer_out(self.VQC['forget'](gates)))\n",
        "\n",
        "            cy = tf.math.multiply(cx, forgetgate) + tf.math.multiply(ingate, cellgate)\n",
        "            hy = tf.math.multiply(outgate, keras.activations.tanh(cy))\n",
        "\n",
        "        return (hy, cy)\n"
      ],
      "metadata": {
        "id": "0rITPPrnS7mh"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "QL = QLSTMCell(8, 8, 16)"
      ],
      "metadata": {
        "id": "PP4FCQvgS7od"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "QL([[152], [191]], [[[14003], [3356]], [[16025], [3332]]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-CN6toW7akhV",
        "outputId": "566d7a73-d216-402f-b528-a8bb74c70d89"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(2, 16), dtype=float32, numpy=\n",
              " array([[0.49785537, 0.5111109 , 0.50267434, 0.48306435, 0.4997821 ,\n",
              "         0.54256725, 0.53681946, 0.47413915, 0.50309986, 0.51466304,\n",
              "         0.4859694 , 0.4678425 , 0.53466487, 0.49068442, 0.50893986,\n",
              "         0.49183512],\n",
              "        [0.4705162 , 0.5169401 , 0.54420304, 0.4806176 , 0.5392125 ,\n",
              "         0.45226473, 0.4879713 , 0.53293705, 0.50252223, 0.54763067,\n",
              "         0.5468684 , 0.5714903 , 0.45921072, 0.49655184, 0.4488556 ,\n",
              "         0.5574867 ]], dtype=float32)>,\n",
              " <tf.Tensor: shape=(2, 16), dtype=float32, numpy=\n",
              " array([[7871.2744, 8014.5356, 8092.75  , 7866.7485, 8050.4917, 8327.298 ,\n",
              "         8325.258 , 7784.384 , 7990.8037, 8135.0366, 7840.888 , 7825.442 ,\n",
              "         8283.218 , 7905.5854, 8006.092 , 7930.255 ],\n",
              "        [1531.287 , 1722.0348, 1786.6824, 1629.1345, 1794.9073, 1543.3058,\n",
              "         1656.9673, 1772.2563, 1703.1938, 1784.28  , 1792.6654, 1930.8656,\n",
              "         1504.2983, 1646.7672, 1484.5356, 1845.7428]], dtype=float32)>)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "QL.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CV3u9fVzcBsc",
        "outputId": "3219a8f5-d95b-460e-b48f-89df1f71b115"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"qlstm_cell\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_3 (Dense)             multiple                  48        \n",
            "                                                                 \n",
            " keras_layer (KerasLayer)    multiple                  16        \n",
            "                                                                 \n",
            " keras_layer_1 (KerasLayer)  multiple                  16        \n",
            "                                                                 \n",
            " keras_layer_3 (KerasLayer)  multiple                  16        \n",
            "                                                                 \n",
            " keras_layer_2 (KerasLayer)  multiple                  16        \n",
            "                                                                 \n",
            " dense_4 (Dense)             multiple                  256       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 368\n",
            "Trainable params: 368\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Actual Generator - VERY BUGGY"
      ],
      "metadata": {
        "id": "MzGJRlilcqDp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GraphGenerator(keras.Model):\n",
        "    def __init__(self, H_inputs, H, z_dim, N, rw_len, temp):\n",
        "        '''\n",
        "            H_inputs: input dimension\n",
        "            H:        hidden dimension\n",
        "            z_dim:    latent dimension\n",
        "            N:        number of nodes (needed for the up and down projection)\n",
        "            rw_len:   number of LSTM cells\n",
        "            temp:     temperature for the gumbel softmax\n",
        "        '''\n",
        "        super(GraphGenerator, self).__init__()\n",
        "        self.intermediate = keras.layers.Dense(H)\n",
        "        self.c_up = keras.layers.Dense(H)\n",
        "        self.h_up = keras.layers.Dense(H)\n",
        "        self.qlstm = QLSTMCell(input_size=H_inputs, hidden_size=H, n_qubits=N)\n",
        "        self.W_up = keras.layers.Dense(N)\n",
        "        self.W_down = keras.layers.Dense(H_inputs, use_bias=False)\n",
        "        self.rw_len = rw_len\n",
        "        self.temp = temp\n",
        "        self.H, self.N = H, N\n",
        "        self.H_inputs = H_inputs\n",
        "        self.latent_dim = z_dim\n",
        "\n",
        "    def sample_latent(self, num_samples):\n",
        "        return tf.random.normal([num_samples, self.latent_dim])\n",
        "\n",
        "    # I HAVE NO IDEA HOW TO DO THIS IN TENSORFLOW\n",
        "    def init_hidden(self, batch_sz):\n",
        "        weight = next(self.parameters).data\n",
        "        return weight.new(batch_sz, self.H_inputs).zero_()\n",
        "    # HELP WITH FUNCTION ABOVE\n",
        "\n",
        "    def sample_gumbel(self, logits, eps=1e-20):\n",
        "        U = tf.random.normal([logits.shape])\n",
        "        return -tf.math.log(-tf.math.log(U + eps) + eps)\n",
        "\n",
        "    def gumbel_softmax(self, logits, temp):\n",
        "        gumbel = self.sample_gumbel(logits)\n",
        "        y = logits + gumbel\n",
        "        y = tf.nn.softmax(y / temp, axis=1)\n",
        "        return y\n",
        "\n",
        "    def call(self, latent, inputs):\n",
        "        intermediate = keras.activations.tanh(self.intermediate(latent))\n",
        "        hc = (\n",
        "            keras.activations.tanh(self.h_up(intermediate)),\n",
        "            keras.activations.tanh(self.c_up(intermediate))\n",
        "        )\n",
        "        out = []\n",
        "        for i in range(self.rw_len):\n",
        "            hh, cc = self.qlstm(inputs, hc)\n",
        "            hc = (hh, cc)\n",
        "            h_up = self.W_up(hh)\n",
        "            h_sample = self.gumbel_softmax(h_up, self.temp)\n",
        "            inputs = self.W_down(h_sample)\n",
        "            out.append(h_sample)\n",
        "        return tf.stack(out, axis=1)\n",
        "\n",
        "    def sample_reg(self, num_samples):\n",
        "        noise = self.sample_latent(num_samples)\n",
        "        inp_zeroes = self.init_hidden(num_samples)\n",
        "        gen_data = self(noise, inp_zeroes)\n",
        "        return gen_data\n",
        "\n",
        "    #Not sure if this works\n",
        "    def sample_disc(self, num_samples):\n",
        "        proba = tf.stop_gradient(self.sample_reg(num_samples))\n",
        "        return np.argmax(proba.numpy(), axis=2)\n"
      ],
      "metadata": {
        "id": "JMBKE42McsZW"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "QG = GraphGenerator(16, 16, 16, 16, 1, 0.5)"
      ],
      "metadata": {
        "id": "NRFCejKM_Dt4"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "QG([314.1592653], [7438, 9465])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 412
        },
        "id": "M_nFe1vWCDjc",
        "outputId": "318dda22-feda-41a5-de13-906bb26db202"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-68-2213850f1ca5>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mQG\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m314.1592653\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m7438\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m9465\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-65-a4a893c2ea97>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, latent, inputs)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlatent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0mintermediate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintermediate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlatent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         hc = (\n\u001b[1;32m     46\u001b[0m             \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mh_up\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mintermediate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling layer 'graph_generator_3' (type GraphGenerator).\n\nInput 0 of layer \"dense_39\" is incompatible with the layer: expected min_ndim=2, found ndim=0. Full shape received: ()\n\nCall arguments received by layer 'graph_generator_3' (type GraphGenerator):\n  • latent=['tf.Tensor(shape=(), dtype=float32)']\n  • inputs=['7438', '9465']"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Graph Discriminator"
      ],
      "metadata": {
        "id": "0KR8AUItsY_G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Relational Graph Convolution Layer"
      ],
      "metadata": {
        "id": "TE7iqFmesmY8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RelationalGraphConvLayer(keras.layers.Layer):\n",
        "    def __init__(\n",
        "        self,\n",
        "        units=128,\n",
        "        activation=\"relu\",\n",
        "        use_bias=False,\n",
        "        kernel_initializer=\"glorot_uniform\",\n",
        "        bias_initializer=\"zeros\",\n",
        "        kernel_regularizer=None,\n",
        "        bias_regularizer=None,\n",
        "        **kwargs\n",
        "    ):\n",
        "        super().__init__(**kwargs)\n",
        "\n",
        "        self.units = units\n",
        "        self.activation = keras.activations.get(activation)\n",
        "        self.use_bias = use_bias\n",
        "        self.kernel_initializer = keras.initializers.get(kernel_initializer)\n",
        "        self.bias_initializer = keras.initializers.get(bias_initializer)\n",
        "        self.kernel_regularizer = keras.regularizers.get(kernel_regularizer)\n",
        "        self.bias_regularizer = keras.regularizers.get(bias_regularizer)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        bond_dim = input_shape[0][1]\n",
        "        atom_dim = input_shape[1][2]\n",
        "\n",
        "        self.kernel = self.add_weight(\n",
        "            shape=(bond_dim, atom_dim, self.units),\n",
        "            initializer=self.kernel_initializer,\n",
        "            regularizer=self.kernel_regularizer,\n",
        "            trainable=True,\n",
        "            name=\"W\",\n",
        "            dtype=tf.float32,\n",
        "        )\n",
        "\n",
        "        if self.use_bias:\n",
        "            self.bias = self.add_weight(\n",
        "                shape=(bond_dim, 1, self.units),\n",
        "                initializer=self.bias_initializer,\n",
        "                regularizer=self.bias_regularizer,\n",
        "                trainable=True,\n",
        "                name=\"b\",\n",
        "                dtype=tf.float32,\n",
        "            )\n",
        "\n",
        "        self.built = True\n",
        "\n",
        "    def call(self, inputs, training=False):\n",
        "        adjacency, features = inputs\n",
        "        # Aggregate information from neighbors\n",
        "        x = tf.matmul(adjacency, features[:, None, :, :])\n",
        "        # Apply linear transformation\n",
        "        x = tf.matmul(x, self.kernel)\n",
        "        if self.use_bias:\n",
        "            x += self.bias\n",
        "        # Reduce bond types dim\n",
        "        x_reduced = tf.reduce_sum(x, axis=1)\n",
        "        # Apply non-linear transformation\n",
        "        return self.activation(x_reduced)"
      ],
      "metadata": {
        "id": "e8mcj6yKsmBn"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Actual Disciminator"
      ],
      "metadata": {
        "id": "4o9_tVWvc5la"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def GraphDiscriminator(\n",
        "    gconv_units, dense_units, dropout_rate, adjacency_shape, feature_shape\n",
        "):\n",
        "\n",
        "    adjacency = keras.layers.Input(shape=adjacency_shape)\n",
        "    features = keras.layers.Input(shape=feature_shape)\n",
        "\n",
        "    # Propagate through one or more graph convolutional layers\n",
        "    features_transformed = features\n",
        "    for units in gconv_units:\n",
        "        features_transformed = RelationalGraphConvLayer(units)(\n",
        "            [adjacency, features_transformed]\n",
        "        )\n",
        "\n",
        "    # Reduce 2-D representation of molecule to 1-D\n",
        "    x = keras.layers.GlobalAveragePooling1D()(features_transformed)\n",
        "\n",
        "    # Propagate through one or more densely connected layers\n",
        "    for units in dense_units:\n",
        "        x = keras.layers.Dense(units, activation=\"relu\")(x)\n",
        "        x = keras.layers.Dropout(dropout_rate)(x)\n",
        "\n",
        "    # For each molecule, output a single scalar value expressing the\n",
        "    # \"realness\" of the inputted molecule\n",
        "    x_out = keras.layers.Dense(1, dtype=\"float32\")(x)\n",
        "\n",
        "    return keras.Model(inputs=[adjacency, features], outputs=x_out)"
      ],
      "metadata": {
        "id": "EoGwuG_4ssSi"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_ATOMS = 9  # Maximum number of atoms\n",
        "ATOM_DIM = 4 + 1  # Number of atom types\n",
        "BOND_DIM = 4 + 1  # Number of bond types\n",
        "LATENT_DIM = 64  # Size of the latent space"
      ],
      "metadata": {
        "id": "-g65ctOtejpv"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "discriminator = GraphDiscriminator(\n",
        "    gconv_units=[128, 128, 128, 128],\n",
        "    dense_units=[512, 512],\n",
        "    dropout_rate=0.2,\n",
        "    adjacency_shape=(BOND_DIM, NUM_ATOMS, NUM_ATOMS),\n",
        "    feature_shape=(NUM_ATOMS, ATOM_DIM),\n",
        ")"
      ],
      "metadata": {
        "id": "-rZ45pY-d_84"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "discriminator.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EYaKlhUeem0B",
        "outputId": "c0146d8a-5686-47d3-8663-585a57c581d5"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 5, 9, 9)]    0           []                               \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)           [(None, 9, 5)]       0           []                               \n",
            "                                                                                                  \n",
            " relational_graph_conv_layer (R  (None, 9, 128)      3200        ['input_1[0][0]',                \n",
            " elationalGraphConvLayer)                                         'input_2[0][0]']                \n",
            "                                                                                                  \n",
            " relational_graph_conv_layer_1   (None, 9, 128)      81920       ['input_1[0][0]',                \n",
            " (RelationalGraphConvLayer)                                       'relational_graph_conv_layer[0][\n",
            "                                                                 0]']                             \n",
            "                                                                                                  \n",
            " relational_graph_conv_layer_2   (None, 9, 128)      81920       ['input_1[0][0]',                \n",
            " (RelationalGraphConvLayer)                                       'relational_graph_conv_layer_1[0\n",
            "                                                                 ][0]']                           \n",
            "                                                                                                  \n",
            " relational_graph_conv_layer_3   (None, 9, 128)      81920       ['input_1[0][0]',                \n",
            " (RelationalGraphConvLayer)                                       'relational_graph_conv_layer_2[0\n",
            "                                                                 ][0]']                           \n",
            "                                                                                                  \n",
            " global_average_pooling1d (Glob  (None, 128)         0           ['relational_graph_conv_layer_3[0\n",
            " alAveragePooling1D)                                             ][0]']                           \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 512)          66048       ['global_average_pooling1d[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " dropout (Dropout)              (None, 512)          0           ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 512)          262656      ['dropout[0][0]']                \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)            (None, 512)          0           ['dense_1[0][0]']                \n",
            "                                                                                                  \n",
            " dense_2 (Dense)                (None, 1)            513         ['dropout_1[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 578,177\n",
            "Trainable params: 578,177\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Compile Final Model - TODO"
      ],
      "metadata": {
        "id": "6AhT_4VcswXo"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bZ4n7CVLsvv5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}